{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Pushshift API\n",
    "\n",
    "Pushshift is a service that archives and indexes Reddit at regular intervals. It allows for higher-level search functionality and querying for Reddit comments and submissions, facilitating data collection for analysis and modeling. It leverages the requests library to return a json response that can then be parsed for the data of interest.\n",
    "\n",
    "Resources: \n",
    "- Pushshift Endpoints: https://pushshift.io/\n",
    "- Pushshift Documentation: https://github.com/pushshift/api\n",
    "- Pushshift Subreddit: https://www.reddit.com/r/pushshift/comments/89pxra/pushshift_api_with_large_amounts_of_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, csv, json, re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the base query syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the query url to the pushshift api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters for the query. A full list of parameters can be found on: https://pushshift.io/api-parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'searchType':'submission',\n",
    "          'subreddit':'lifeprotips, unethicallifeprotips',\n",
    "          'sort':'desc',\n",
    "          'size':10,\n",
    "#           'before': '10d',\n",
    "#           'after': '168d',\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the url to make sure the query terms are correct and the server is responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status code returned from the server is 200, meaning the query was accepted and there aren't any connection issues. Checking length of the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.json()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length is 10, as expected. Assessing the file structure for keys of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'evolutiontoe',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_zyeq9i1',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'I discovered this a while back too. Which  has has been awesome. Since it takes me months to finish a book. Because if Reddit!!!',\n",
       "  'created_utc': 1554086088,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejulcpz',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7tthl',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't3_b7tthl',\n",
       "  'permalink': '/r/LifeProTips/comments/b7tthl/lpt_if_your_digital_library_loan_expires_before/ejulcpz/',\n",
       "  'retrieved_on': 1554086089,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'ImS0hungry',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_4b73e',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'This is also dependant on the email retention policy. My firm scrubs emails older than 6mos.',\n",
       "  'created_utc': 1554086083,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejulcij',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_ejtpp8l',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejulcij/',\n",
       "  'retrieved_on': 1554086084,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'aether28',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_l82zz',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'Actual advice mallard has come out of retirement!',\n",
       "  'created_utc': 1554086079,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejulcdb',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7q6oh',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_ejtluh2',\n",
       "  'permalink': '/r/LifeProTips/comments/b7q6oh/lpt_april_fools_day_has_started_in_some_parts_of/ejulcdb/',\n",
       "  'retrieved_on': 1554086080,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'niisyth',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_xb531',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'Did I just witness a comment thread on which produce has the best boxes?? ',\n",
       "  'created_utc': 1554086075,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejulc6g',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7mtn7',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_ejtfdmh',\n",
       "  'permalink': '/r/LifeProTips/comments/b7mtn7/lpt_moving_go_to_your_local_24hr_super_store/ejulc6g/',\n",
       "  'retrieved_on': 1554086076,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'mangz74',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_iv21f',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'Use OneNote or something similar instead of using a dead tree. Can be shared and sent via email as proof.',\n",
       "  'created_utc': 1554086058,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejulbjk',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't3_b7pe61',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejulbjk/',\n",
       "  'retrieved_on': 1554086059,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'UncleFlip',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_bmpth',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': 'Iâ€™d hate to work somewhere I had to do this. I will occasionally send the CYA email in certain situations. ',\n",
       "  'created_utc': 1554086024,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejula4q',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_ejtmg4j',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejula4q/',\n",
       "  'retrieved_on': 1554086025,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'rethra_',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_2jxup0y1',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': \"I do tbis religiously. Your memory will also improve along the way. I've basically outlined the entire history of my company, wrote out ever context and process in case I need to revisit. Saved my ass multiple times and basically mirrored everything on the cctv. No one doubts when I offer historical input.\",\n",
       "  'created_utc': 1554085997,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejul8zn',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't3_b7pe61',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejul8zn/',\n",
       "  'retrieved_on': 1554085999,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'perfect_square',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_cxwit',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': '\"Trump\\'s address to the press included TWO complete, coherent sentences\". ',\n",
       "  'created_utc': 1554085985,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejul8i9',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7q6oh',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't3_b7q6oh',\n",
       "  'permalink': '/r/LifeProTips/comments/b7q6oh/lpt_april_fools_day_has_started_in_some_parts_of/ejul8i9/',\n",
       "  'retrieved_on': 1554085986,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'Spline_reticulation',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_2zo83onj',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': \"Yup, that's how we do it in med device development.\",\n",
       "  'created_utc': 1554085969,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejul7vg',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_eju2i2z',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejul7vg/',\n",
       "  'retrieved_on': 1554085969,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'},\n",
       " {'author': 'RobotSlaps',\n",
       "  'author_flair_background_color': None,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'author_flair_template_id': None,\n",
       "  'author_flair_text': None,\n",
       "  'author_flair_text_color': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'author_fullname': 't2_15pdo7',\n",
       "  'author_patreon_flair': False,\n",
       "  'body': \"Well, let's just dump it in the sewer and say we delivered it.\",\n",
       "  'created_utc': 1554085954,\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'id': 'ejul79h',\n",
       "  'is_submitter': False,\n",
       "  'link_id': 't3_b7pe61',\n",
       "  'no_follow': True,\n",
       "  'parent_id': 't1_ejtwtup',\n",
       "  'permalink': '/r/LifeProTips/comments/b7pe61/lpt_work_in_an_office_buy_a_3_notebook_and/ejul79h/',\n",
       "  'retrieved_on': 1554085955,\n",
       "  'score': 1,\n",
       "  'send_replies': True,\n",
       "  'stickied': False,\n",
       "  'subreddit': 'LifeProTips',\n",
       "  'subreddit_id': 't5_2s5oq'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys of interest are:\n",
    "- author\n",
    "- body\n",
    "- retrieved_on\n",
    "- created_utc\n",
    "- link_id\n",
    "- parent_id\n",
    "- permalink\n",
    "- subreddit\n",
    "- subreddit_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['author',\n",
    "            'body',\n",
    "            'retrieved_on'\n",
    "            'subreddit',\n",
    "            'subreddit_id',\n",
    "            'created_utc',\n",
    "            'retrieved_on',\n",
    "            'link_id',\n",
    "            'parent_id',\n",
    "            'permalink',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Querying Reddit and saving raw data in .json format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function for creating a logfile and formatting file names with a unique timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[a-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Pull: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function for collecting comments and parsing into a dataframe with the features of interest, saving out the raw data for each pull. Request loop inspired: [(Source)](https://www.reddit.com/r/pushshift/comments/89pxra/pushshift_api_with_large_amounts_of_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_query(subreddits, n_samples=30000, searchType='submission', before=None, after=None):\n",
    "    url = f'https://api.pushshift.io/reddit/search/'\n",
    "    last_comment = round(time.time())\n",
    "    comment_list = []\n",
    "    \n",
    "    run = 1\n",
    "    while len(comment_list) < n_samples:\n",
    "        \n",
    "        try:\n",
    "            print(f'Starting query {run}')\n",
    "            \n",
    "            params = {'searchType':searchType,\n",
    "              'subreddit':subreddits,\n",
    "              'sort':'desc',\n",
    "              'size':1000,\n",
    "              'before': last_comment-1,\n",
    "              'after':after,\n",
    "             }\n",
    "                \n",
    "            response = requests.get(url, params = params)\n",
    "            posts = response.json()['data']\n",
    "            \n",
    "            if len(posts) == 0:\n",
    "                last_comment = last_comment\n",
    "            else:\n",
    "                last_comment = posts[-1]['created_utc']\n",
    "                comment_list.extend(posts)\n",
    "                timestamp = posts[-1]['created_utc']\n",
    "                time.sleep(1) \n",
    "                run += 1\n",
    "        except:\n",
    "            if response.status_code != 200:\n",
    "                return f'Check status. Error code: {response.status_code}'\n",
    "            else:\n",
    "                return 'Error. Pull not completed.'\n",
    "    \n",
    "    formatted_name, now, file_description = filename_format_log(file_path =f'../data/raw_{searchType}s.json', now=timestamp)\n",
    "    with open(formatted_name, 'w+') as f:\n",
    "        json.dump(comment_list, f)\n",
    "    \n",
    "    print(f'Saved and completed query and returned {len(comment_list)} {searchType}s.')\n",
    "    print(f'Reddit text is ready for processing.')\n",
    "    return print(f'Last timestamp was {timestamp}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the query function to collect 15 comments from the conservative subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query 16\n",
      "Starting query 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error. Pull not completed.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_query(subreddits='lifeprotips, unethicallifeprotips',\n",
    "             n_samples=30000,\n",
    "             searchType='submission',\n",
    "#              before = '10d',\n",
    "#              after = '168d'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1553699454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/1553206537_raw_comments.json', 'r') as f:\n",
    "    bo_comment_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bo_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_comment_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the json file into a dataframe containing the features of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_parse(sample):\n",
    "    \n",
    "    col_list = ['author',\n",
    "                'body',\n",
    "                'subreddit',\n",
    "                'subreddit_id',\n",
    "                'created_utc',\n",
    "                'link_id',\n",
    "                'parent_id',\n",
    "                'permalink',\n",
    "                ]\n",
    "    \n",
    "    df = pd.DataFrame(sample)\n",
    "    df = df[col_list]\n",
    "    \n",
    "    df.rename(columns={'subreddit':'lifeprotips'}, inplace=True)\n",
    "    df['lifeprotips'] = comments_df['lifeprotips'].map({'unethicallifeprotips':0, 'lifeprotips':1})\n",
    "    \n",
    "    col_order = ['author',\n",
    "                 'body',\n",
    "                 'blackops4',\n",
    "                 'created_utc',\n",
    "                 'subreddit_id',\n",
    "                 'parent_id',\n",
    "                 'link_id',\n",
    "                 'permalink',\n",
    "                ]\n",
    "\n",
    "    return df[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the shape of the dataframe to ensure correct transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = reddit_parse(bo_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape corresponds with expected values. Reviewing the head of the dataframe to ensure data was correctly labeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['body'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['author'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['created_utc'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['created_utc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1553206319, 1553897404]\n",
    "start_end = [time.asctime(time.gmtime(i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
